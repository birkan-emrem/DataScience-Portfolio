{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55600496",
   "metadata": {},
   "source": [
    "## Deep Learning: Logistic Regression\n",
    "\n",
    "In this project, we will utilize the synthetic dinosaur dataset that was previously employed for logistic regression in the machine learning section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15acdb1d",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d556798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Head_Size</th>\n",
       "      <th>Teeth_Size</th>\n",
       "      <th>Dinosaur_Length</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spinosaurus</td>\n",
       "      <td>1.44</td>\n",
       "      <td>15.27</td>\n",
       "      <td>13.31</td>\n",
       "      <td>8183.39</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spinosaurus</td>\n",
       "      <td>1.55</td>\n",
       "      <td>16.38</td>\n",
       "      <td>13.16</td>\n",
       "      <td>8290.08</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Triceratops</td>\n",
       "      <td>1.91</td>\n",
       "      <td>17.16</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8212.46</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TREX</td>\n",
       "      <td>1.42</td>\n",
       "      <td>15.25</td>\n",
       "      <td>11.71</td>\n",
       "      <td>6722.90</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Triceratops</td>\n",
       "      <td>2.13</td>\n",
       "      <td>16.44</td>\n",
       "      <td>6.40</td>\n",
       "      <td>7911.30</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type  Head_Size  Teeth_Size  Dinosaur_Length   Weight  Gender  Class\n",
       "0  Spinosaurus       1.44       15.27            13.31  8183.39  Female      2\n",
       "1  Spinosaurus       1.55       16.38            13.16  8290.08    Male      2\n",
       "2  Triceratops       1.91       17.16             8.76  8212.46    Male      3\n",
       "3         TREX       1.42       15.25            11.71  6722.90  Female      1\n",
       "4  Triceratops       2.13       16.44             6.40  7911.30  Female      3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dinosaurs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ebea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Head_Size', 'Teeth_Size', 'Dinosaur_Length', 'Weight', 'Class']].to_csv('dinosaurs_new.csv', \n",
    "                                                                            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb69405",
   "metadata": {},
   "source": [
    "Here, it's clear that our dataset comprises four features and 6100 data points, all of which are devoid of any `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bf520",
   "metadata": {},
   "source": [
    "## 2. Deep Learning: Linear Regression\n",
    "\n",
    "To begin, we will import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b2644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75d419",
   "metadata": {},
   "source": [
    "Next, we will create a dataset class. Our class will consist of three methods:\n",
    "\n",
    "1. ____init____(self, csv_file): This is the constructor method that initializes the dataset object when an instance is created. It takes a single argument csv_file, which is the path to the CSV file containing the dataset.\n",
    "2. ____len____(self): This method is used to determine the length of the dataset, i.e., the total number of samples.\n",
    "3. ____getitem____(self, idx): This method is used to retrieve an individual sample from the dataset. It takes an index idx as an argument, indicating which sample to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a935eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.features = data.iloc[:, :-1].values\n",
    "        self.labels = data.iloc[:, -1].values - 1  \n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4357f22",
   "metadata": {},
   "source": [
    "We will pass the dinosaurs_new.csv file that we created in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6838156",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'dinosaurs_new.csv'  \n",
    "dataset = CustomDataset(csv_file)\n",
    "\n",
    "# Create a data loader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fce34e",
   "metadata": {},
   "source": [
    "Next, we will construct a logistic regression regression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a102cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "     def __init__(self, input_size, num_classes):\n",
    "         super(LogisticRegression, self).__init__()\n",
    "         self.linear = torch.nn.Linear(input_size, num_classes)     \n",
    "            \n",
    "     def forward(self, x):\n",
    "         outputs = torch.sigmoid(self.linear(x))\n",
    "         return outputs    \n",
    "    \n",
    "    \n",
    "# Initialize model and define loss function\n",
    "input_size = dataset.features.shape[1]\n",
    "num_classes = len(set(dataset.labels))\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711e2c3",
   "metadata": {},
   "source": [
    "Lastly, we will create the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb41a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/250] - Average Loss: 0.8432 - Accuracy: 92.10%\n",
      "Epoch [100/250] - Average Loss: 0.7529 - Accuracy: 96.52%\n",
      "Epoch [150/250] - Average Loss: 0.7119 - Accuracy: 97.08%\n",
      "Epoch [200/250] - Average Loss: 0.6885 - Accuracy: 97.13%\n",
      "Epoch [250/250] - Average Loss: 0.6730 - Accuracy: 97.39%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 250\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / len(dataset) * 100\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {average_loss:.4f} - Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa720a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
